*------------------------------------------------------------*
* Training Log
Date:                October 16, 2018
Time:                22:35:01
*------------------------------------------------------------*
15207  proc freq data=EMWS1.TextTopic_VariableSet noprint;
15208  table ROLE*LEVEL/out=WORK.TextTopicMETA;
15209  run;

NOTE: There were 1 observations read from the data set EMWS1.TEXTTOPIC_VARIABLESET.
NOTE: The data set WORK.TEXTTOPICMETA has 1 observations and 4 variables.
NOTE: PROCEDURE FREQ used (Total process time):
      real time           0.12 seconds
      cpu time            0.03 seconds
      

15210  proc print data=WORK.TextTopicMETA label noobs;
15211  var ROLE LEVEL COUNT;
15212  label ROLE = "%sysfunc(sasmsg(sashelp.dmine, meta_role_vlabel, NOQUOTE))" LEVEL = "%sysfunc(sasmsg(sashelp.dmine, meta_level_vlabel, NOQUOTE))" COUNT = "%sysfunc(sasmsg(sashelp.dmine, rpt_count_vlabel, NOQUOTE))";
15213  title9 ' ';
15214  title10 "%sysfunc(sasmsg(sashelp.dmine, rpt_varSummary_title  , NOQUOTE))";
15215  run;

NOTE: There were 1 observations read from the data set WORK.TEXTTOPICMETA.
NOTE: The PROCEDURE PRINT printed page 1.
NOTE: PROCEDURE PRINT used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

15216  title10;

15217  %let EMEXCEPTIONSTRING=;
PERFORMANCE  DETAILS
15562  *------------------------------------------------------------*;
15563  * TextTopic: Generation of macros and macro variables;
15564  * To see the code generated, set the EM_DEBUG macro variable to SOURCE or _ALL_;
15565  *------------------------------------------------------------*;

15566  %let EMEXCEPTIONSTRING=;
15567  *------------------------------------------------------------*;
15568  * TRAIN: TextTopic;
15569  *------------------------------------------------------------*;
15570  %let EM_ACTION = TRAIN;
15571  %let syscc = 0;
15572  %macro main;
15573      %if %upcase(&EM_ACTION) = CREATE %then %do;
15574          filename temp catalog 'sashelp.emtxtext.topic_create.source';
15575          %include temp;
15576          %create;
15577      %end;
15578      %if %upcase(&EM_ACTION) = TRAIN %then %do;
15579          filename temp catalog 'sashelp.emtxtext.topic_train.source';
15580          %include temp;
15581          %train;
15582      %end;
15583     %if %upcase(&EM_ACTION) = SCORE %then %do;
15584          filename temp catalog 'sashelp.emtxtext.topic_score.source';
15585          %include temp;
15586          %score;
15587      %end;
15588      %if %upcase(&EM_ACTION) = REPORT %then %do;
15589          filename temp catalog 'sashelp.emtxtext.topic_report.source';
15590          %include temp;
15591          %report;
15592      %end;
15593  %mend main;
15594  
15595  %main;
NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.TOPIC_TRAIN.SOURCE.
15596 +/* ****************************************************************
15597 + * Copyright (C) 2009 by SAS Institute Inc., Cary, NC 27513
15598 + *
15599 + * Name:             topic_train.sas
15600 + * Support:          cox  James A. Cox
15601 + * Product:          SAS Text Miner
15602 + * Language:         Sas
15603 + * Script:
15604 + *
15605 + * Usage:
15606 + *
15607 + * Purpose: Implements the Train action in the Text Topic Node.
15608 + *
15609 + * History:
15610 + * 26May09 Added header [cox]
15611 + *
15612 + * Notes:.
15613 + *
15614 + * Last Modified By:
15615 + * Last Modified On: Tue Oct 25 16:29:22 2016
15616 + *
15617 + * End
15618 + * ************************************************************** */
15619 +%macro train;
15620 +
15621 +   %if ^%symexist(tm_debug) %then %let tm_debug=0;
15622 +    %global last_parse_node last_filter_node last_prescore_node server_err
15623 +      parsevar EM_SASMSG /* EMEXCEPTIONSTRING */ systmutil;
15624 +   %let EM_SASMSG=TMINE;
15625 +   %let syscc=0;
15626 +   %let systmutil = ;
15627 +
15628 +    filename temp catalog 'sashelp.emtxtext.tm_get_last_filter.source';
15629 +    %include temp;
15630 +    %tm_get_last_filter(eminfo=&EM_IMPORT_DATA_EMINFO,em_lib=&em_lib,
15631 +                        em_variableset=&em_data_variableset);
15632 +    %if &EMEXCEPTIONSTRING ne %then %goto end_topic_train;
15633 +    %let lastparsenode=&last_parse_node;
15634 +    %let lastfilternode=&last_filter_node;
15635 +    %let lastprescore=&last_prescore_node;
15636 +
15637 +
15638 +    /*populate last tm node dataset so tm_get_last_filter is not called in score*/
15639 +    %em_getname(key=last_tm_nodes, type=data);
15640 +    data &em_user_last_tm_nodes;
15641 +        set &EM_IMPORT_DATA_EMINFO;
15642 +    run;
15643 +
15644 +    * include helper macros ;
15645 +    filename temp catalog 'sashelp.emtxtext.row_pivot_normalize.source';
15646 +    %include temp;
15647 +
15648 +    filename temp catalog 'sashelp.emtxtext.tmt_topify.sas';
15649 +    %include temp;
15650 +
15651 +    filename temp catalog 'sashelp.emtxtext.tmt_doc_score.source';
15652 +    %include temp;
15653 +
15654 +    filename temp catalog 'sashelp.emtxtext.tmt_remove_dups.source';
15655 +    %include temp;
15656 +
15657 +   /* Tell system that this is not data step score code */
15658 +
15659 +%let EM_PUBLISHCODE = PUBLISH;
15660 +%let EM_SCORECODEFORMAT = DATASTEP;
15661 +
15662 +    * get input data sets ;
15663 +
15664 +    %em_getname(key=terms,         type=data);
15665 +    %em_getname(key=tmout,         type=data);
15666 +    %em_getname(key=weightedterms, type=data);
15667 +    %em_getname(key=weightedtmout, type=data);
15668 +
15669 +    %em_getname(key=parseVarData, type=data);
15670 +
15671 +    /* Make sure that at least 15 documents are provided */
15672 +   /* Check to make sure that minimum number of documents occur to calculate
15673 +      topics */
15674 +/* This check is done in tmt_multi_terms and is not relevant for times when they are running with user topics */
15675 +/*
15676 +   proc sql noprint; select count(distinct _document_) into :nobs
15677 +      from &em_lib..&lastfilternode._tmout;
15678 +      quit;
15679 +   %if &nobs < 15 %then %do;
15680 +      %let EMEXCEPTIONSTRING = EMTOOL.TOPIC_DATA_SMALL,&nobs;
15681 +      %goto end_topic_train;
15682 +      %end;
15683 +*/
15684 +
15685 +      %global ntopics;
15686 +
15687 +    %em_getname(key=initTopics, type=data);
15688 +
15689 +   /* Note: for the following macro variables, anything that begins with tmt_
15690 +   refers to properties on the TM node, anything that begins with em_ are
15691 +   tables that need to be em_registered, and anything that beings tmm_ are
15692 +   macro variables that the user may or may not set.  If they are not set, then
15693 +   they should default to the value given */
15694 +
15695 +   %em_checkmacro(name=tmm_doccutoff,       global=Y, value=.001);
15696 +      %if &tmm_doccutoff<0 or &tmm_doccutoff>1 %then %let tmm_doccutoff=0.001;
15697 +   %em_checkmacro(name=tmm_termcutoff,       global=Y, value=.001);
15698 +      %if &tmm_termcutoff<0 or &tmm_termcutoff>1
15699 +          %then %let tmm_termcutoff=0.001;
15700 +   %em_checkmacro(name=tmm_norm_pivot,      global=Y, value=.7);
15701 +      %if &tmm_norm_pivot<0 or &tmm_norm_pivot>1 %then %let tmm_norm_pivot=0.7;
15702 +   %em_checkmacro(name=tmm_term_cutoff,      global=Y, value=);
15703 +
15704 +   /* The default value of 35 degrees means that a topic is excluded if at least 2/3 of its variance
15705 +      (i.e. r-squared) is accounted for by the other topic (i.e. sqrt(2/3) ~ arccos(35) )
15706 +    */
15707 +   %em_checkmacro(name=tmm_max_topic_angle, global=Y, value=35);
15708 +   %em_checkmacro(name=tmm_min_docs,      global=Y, value=10);
15709 +  /* Any terms less than this pct. of maximum are excluded */
15710 +   %em_checkmacro(name=tmm_term_cutoff_pct, global=Y, value=.1);
15711 +
15712 +
15713 +
15714 +   %em_getname(key=topics,           type=data);
15715 +   %em_getname(key=termtopics,       type=data);
15716 +   %em_getname(key=docDs,            type=data);
15717 +   %em_getname(key=tmout_normalized, type=data);
15718 +   %em_getname(key=term_sums,        type=data);
15719 +   %em_getname(key=tmout_parent,     type=data);
15720 +
15721 +   %let tmt_num_single=&em_property_topTermCnt;
15722 +   %let tmt_num_multi=&em_property_autoTopicCnt;
15723 +
15724 +   %let em_topics     = &em_user_topics;
15725 +   %let em_termtopics = &em_user_termtopics;
15726 +   %let em_doc_ds     = &em_user_docDs;
15727 +   %let em_norm_out   = &em_user_tmout_normalized;
15728 +   %let em_term_sums  = &em_user_term_sums;
15729 +   %let em_term_ds=&em_user_weightedterms;
15730 +
15731 +   /* Check if initTopics data set exists */
15732 +   %em_getname(key=initTopics, type=data);
15733 +   %em_getname(key=topic_Cutoffs, type=data);
15734 +   %let tmt_init_topics=&em_user_initTopics;
15735 +
15736 +
15737 +   %if ^%sysfunc(exist(&em_user_initTopics)) %then %do;
15738 +   proc sql noprint;
15739 +   create table &em_user_topic_Cutoffs
15740 +      (_name char(100)
15741 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topic_vlabel, NOQUOTE))",
15742 +       _termcutoff decimal
15743 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_termCutoff_vlabel, NOQUOTE))",
15744 +       _doccutoff decimal
15745 +          label="%sysfunc(sasmsg(sashelp.tmine, rpt_text_docCutoff_vlabel, NOQUOTE))"
15746 +       );
15747 +   create table &em_user_initTopics
15748 +      (_topic_ char(100)
15749 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_intopic_vlabel, NOQUOTE))",
15750 +       _term_ char(80)
15751 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_intopic_term, NOQUOTE))",
15752 +       _role_ char(32)
15753 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_intopic_role, NOQUOTE))",
15754 +       _weight_ decimal
15755 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_intopic_weight, NOQUOTE))"
15756 +       );
15757 +   quit;
15758 +   %end;
15759 +
15760 +   %else %if ^%sysfunc(exist(&em_user_topic_Cutoffs)) %then %do;
15761 +   proc sql noprint;
15762 +   create table &em_user_topic_Cutoffs
15763 +      (_name char(100)
15764 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topic_vlabel, NOQUOTE))",
15765 +       _termcutoff decimal
15766 +          label="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_termCutoff_vlabel, NOQUOTE))",
15767 +       _doccutoff decimal
15768 +          label="%sysfunc(sasmsg(sashelp.tmine, rpt_text_docCutoff_vlabel, NOQUOTE))"
15769 +       );
15770 +   quit;
15771 +   %end;
15772 +
15773 +   /*--------------- Following is training code -------------------- */
15774 +   /* First thing to do is create a weighted out data set if one has not already
15775 +     been created in Text Filter node.  Then make sure you have the out data set
15776 +     as the version that has children rolled up to parents and dropped terms
15777 +     removed.
15778 +     Also, make sure you use a term ds that does not include children, the where clause below accomplishes that.
15779 +   */
15780 +   %let syscc=0;
15781 +
15782 +    %let isweight = 0;
15783 +    %let dsid=%sysfunc(open(%str(&em_lib..&lastfilternode._terms)));
15784 +    %if &dsid gt 0 %then %do;
15785 +        %let isweight =%sysfunc(varnum(&dsid, weight));
15786 +        %let rc=%sysfunc(close(&dsid));
15787 +    %end;
15788 +
15789 +      /* get target variable info */
15790 +      %let targetvar = ;
15791 +      data _null_;
15792 +      set &em_data_variableset(where=(ROLE='TARGET' and USE in('Y' 'D')
15793 +                                      and LEVEL ne 'INTERVAL'));
15794 +      if _N_=1 then call symput('targetvar', strip(NAME));
15795 +      run;
15796 +      data _null_;
15797 +         cellwgt="LOG";
15798 +         set &em_lib..&lastfilternode._tmconfig;
15799 +         call symput('cellwgt',cellwgt);
15800 +         run;
15801 +
15802 +    /* Output weighted, parent-only term and out data set. */
15803 +    proc tmutil data=&em_lib..&lastfilternode._tmout key=&em_lib..&lastfilternode._terms
15804 +        %if &targetvar ne %then doc=&EM_IMPORT_DATA target=&targetvar ;;
15805 +        control init memloc='tmutil_memloc';
15806 +    proc tmutil;
15807 +        control release memloc='tmutil_memloc';
15808 +
15809 +
15810 +    %if "&isweight" eq "0" %then %do;
15811 +       weight termwgt=%if &targetvar= %then entropy; %else MI; cellwgt=&cellwgt;
15812 +       %if &lastfilternode = &lastparsenode %then select reducef=4;;
15813 +       output keeponly keyformat=tmscore out=&EM_USER_weightedtmout key=&em_user_terms;
15814 +       run;
15815 +       %if "%ktrim(&systmutil)" ne "" %then %goto pre_end_topic_train;
15816 +       proc sql noprint;
15817 +           %if ^%sysfunc(exist(&em_user_weightedTerms,'view')) %then drop view &em_user_weightedterms;;
15818 +           create table &em_user_weightedterms as
15819 +              select a.weight, b.*
15820 +              from &em_user_terms as a, &em_lib..&lastfilternode._terms as b
15821 +              where a.key=b.key and a.parent = . and b._ispar ne '.'
15822 +              order by key;
15823 +           quit;
15824 +       %end;
15825 +    %else %do;
15826 +       /* Apply weights on current term table */
15827 +       /******* look up weight from tmconfig table! */
15828 +       weight cellwgt=&cellwgt
15829 +          in_weight=&em_lib..&lastfilternode._terms_data(keep=key weight);
15830 +        output keeponly keyformat=tmscore out=&EM_USER_weightedtmout;
15831 +       run;
15832 +       %if "%ktrim(&systmutil)" ne "" %then %goto pre_end_topic_train;
15833 +       proc sql noprint;
15834 +       %if ^%sysfunc(exist(&em_user_weightedTerms,'view')) %then drop view &em_user_weightedterms;;
15835 +       create table &em_user_weightedterms as
15836 +          select * from &em_lib..&lastfilternode._terms where _ispar ne '.'
15837 +          order by key;
15838 +       quit;
15839 +       %end;
15840 +
15841 +    %if %eval(&syscc)>4 %then %do;
15842 +        %let  EMEXCEPTIONSTRING = exception.server.EMTOOL.GENERICRUNTIMEEXCEPTION;
15843 +       %goto end_topic_train;
15844 +    %end;
15845 +
15846 +   /* Normalize the weighted out data set (containing only kept non-child terms)
15847 +      so that documents have a length of approximately 1 */
15848 +       %if &tmm_norm_pivot ne 0 %then %do;
15849 +           %row_pivot_normalize(transds=&em_user_weightedtmout,
15850 +                     outtransds=&em_norm_out,
15851 +                     col_sumds=&em_term_sums,
15852 +                     row=_document_,col=_termnum_,entry=_count_,
15853 +                     pivot=&tmm_norm_pivot,
15854 +                     tmt_config=&em_lib..&lastfilternode._tmconfig,
15855 +                     tmt_train=1, prefix=&EM_NODEID.);
15856 +          %end;
15857 +       %else %do;
15858 +          data &em_norm_out; set &em_user_weightedtmout; run;
15859 +          %end;
15860 +
15861 +
15862 +    %if %eval(&syscc)>4 %then %do;
15863 +        %let  EMEXCEPTIONSTRING = exception.server.EMTOOL.GENERICRUNTIMEEXCEPTION;
15864 +       %goto end_topic_train;
15865 +    %end;
15866 +
15867 +   %let tmprefix=&EM_NODEID._;
15868 +   %let syscc=0;
15869 +   %let curdocDs=;
15870 +
15871 +   /* If there is an em_init_topics table, call %tmt_topify and _tmt_doc_score,
15872 +                     if not create a completely blank em_term_ds and em_topics
15873 +    */
15874 +
15875 +   %tmt_topify(initds=&tmt_init_topics,termds=&em_term_ds,topicds=&em_topics,
15876 +               termtopicds=&em_termtopics,topic_cutoff_ds=&em_user_topic_Cutoffs,
15877 +               doccutoff=&tmm_doccutoff, termcutoff=&tmm_termcutoff);
15878 +%if &tm_debug =0 %then %do;
15879 +proc sql;
15880 +   drop table _tmptop;
15881 +quit;
15882 +%end;
15883 +   %if %eval(&syscc)>4 %then %do;
15884 +       %let  EMEXCEPTIONSTRING = exception.server.EMTOOL.GENERICRUNTIMEEXCEPTION;
15885 +      %goto end_topic_train;
15886 +   %end;
15887 +
15888 +   proc sql noprint; select count(*) into :ntopics from &em_topics; quit;
15889 +
15890 +   *check for eliminated init topics;
15891 +   proc sql noprint; select count(distinct _topic_) into :user_ntopics from &tmt_init_topics; quit;
15892 +   %if(%eval(&user_ntopics-&ntopics)>0) %then %do;
15893 +        %put &em_codebar;
15894 +         %let errormsg = %sysfunc(sasmsg(sashelp.tmine,EMTOOL.USERTOPIC_NOTE, NOQUOTE,%eval(&user_ntopics-&ntopics), %eval(&user_ntopics-0)));
15895 +        %put &errormsg;
15896 +         %put &em_codebar;
15897 +      %let user_ntopics=&ntopics;
15898 +   %end;
15899 +
15900 +   %tmt_doc_score(termtopds=&em_termtopics,outds=&em_norm_out,
15901 +                  topicds=&em_topics,docds=&em_import_data,newdocds=_userdocs,
15902 +                  termsumds=&em_term_sums, prefix=&tmprefix, pivot=&tmm_norm_pivot);
15903 +    %if %eval(&syscc)>4 %then %do;
15904 +        %let  EMEXCEPTIONSTRING = exception.server.EMTOOL.GENERICRUNTIMEEXCEPTION;
15905 +       %goto end_topic_train;
15906 +    %end;
15907 +
15908 +   %let curdocDs=_userdocs;
15909 +
15910 +   /* be sure docscore dataset is populated if only init docs */
15911 +   data &em_doc_ds; set &curdocDs; run;
15912 +
15913 +   /* If they indicate to create any single term topics, run next three macros,
15914 +      to create single word topics, then score the documents on just those topics,
15915 +      then remove duplicates (based on document scores).  Finally, append new topics and
15916 +      topicterms to respective data sets.  */
15917 +
15918 +    %if "&em_property_topTermCnt" ne "0" %then %do;
15919 +       filename temp catalog 'sashelp.emtxtext.tmt_single_terms.source';
15920 +       %include temp;
15921 +
15922 +       %let syscc=0;
15923 +
15924 +       %tmt_single_terms(termds=&em_term_ds,num_topics=%eval(&tmt_num_single+&user_ntopics),
15925 +                        termtopicds=singtermtop, topicds=singtopics,
15926 +                        startnum=%eval(&ntopics+1),
15927 +                        doccutoff=.001);
15928 +
15929 +        /*get actual number of topics produced*/
15930 +        proc sql noprint; select count(*) into :tmt_act_single from singtopics; quit;
15931 +        %let tmt_act_single=%ktrim(&tmt_act_single);
15932 +
15933 +       %tmt_doc_score(termtopds=singtermtop, docds=&curdocDs,
15934 +                      outds=&em_norm_out, topicds=singtopics, newdocds=_singuserdocs,
15935 +                      termsumds=&em_term_sums, prefix=&tmprefix,
15936 +                      pivot=&tmm_norm_pivot);
15937 +
15938 +       %let _ndel=%eval(&tmt_act_single-&tmt_num_single);
15939 +       %if &_ndel>0 %then %do;
15940 +
15941 +          %tmt_remove_dups(in=_singuserdocs,n=%eval(&user_ntopics+&tmt_act_single),
15942 +                           m=&ntopics,m1=%eval(&ntopics+1),out=&em_doc_ds,
15943 +                           topicds=singtopics, termtopicds=singtermtop,
15944 +                           prefix=&tmprefix.raw,ndel=&_ndel);
15945 +          %let ntopics=%eval(&ntopics+&tmt_act_single-&_ndel);
15946 +          %end;
15947 +           %else %do;
15948 +              %let ntopics=%eval(&ntopics+&tmt_act_single);
15949 +              data &em_doc_ds; set _singuserdocs;
15950 +              %end;
15951 +
15952 +       data &em_topics; set &em_topics singtopics; run;
15953 +       data &em_termtopics; set &em_termtopics singtermtop; run;
15954 +%if &tm_debug =0 %then %do;
15955 +proc sql;
15956 +   drop table singtopics;
15957 +   drop table singtermtop;
15958 +   drop view _tm_termtmpview;
15959 +   drop table _singuserdocs;
15960 +   drop table _tmpdocs;
15961 +   drop table _termview;
15962 +   drop table _termtopics;
15963 +   drop table top_tmp_out;
15964 +   drop table _weighted_tmout;
15965 +   drop table _termsumds;
15966 +quit;
15967 +%end;
15968 +       %if %eval(&syscc)>4 %then %do;
15969 +          %let  EMEXCEPTIONSTRING = exception.server.EMTOOL.GENERICRUNTIMEEXCEPTION;
15970 +          %goto end_topic_train;
15971 +          %end;
15972 +   %end; /*  %if "&em_property_topTermCnt" ne "0" */
15973 +
15974 +
15975 +
15976 +   /* If they indicate to create any multi-term topics, run next three macros */
15977 +   /* The value for rotation= depends on the autoTopic property.  If Yes, then
15978 +      rotation=promax should be used, otherwise rotation=varimax should be used. */
15979 +
15980 +   %if "&em_property_autoTopicCnt" ne "0" %then %do;
15981 +      filename temp catalog 'sashelp.emtxtext.tmt_multi_terms.source';
15982 +      %include temp;
15983 +      proc sql noprint;
15984 +         select count(*) into: _numrepterms
15985 +         from &em_term_ds;
15986 +      quit;
15987 +
15988 +      %if &_numrepterms < 15 %then %do;
15989 +         %let EMEXCEPTIONSTRING = EMTOOL.TOPICTOOFEWTERMS,&_numrepterms;
15990 +         %goto end_topic_train;
15991 +      %end;
15992 +
15993 +        %let syscc=0;
15994 +
15995 +%let startnum=%eval(&ntopics+1);
15996 +      %em_getname(key=out_u, type=data);
15997 +       %tmt_multi_terms(outds=&em_norm_out,termds=&em_term_ds,
15998 +                        num_topics=%eval(&tmt_num_multi+&user_ntopics),termtopicds=mult_termtop,
15999 +                        rotation=
16000 +                            %if &em_property_autoTopic=Y %then promax;
16001 +                        %else varimax;
16002 +                        ,
16003 +                        startnum=&startnum, topicds=mult_topics,
16004 +                        termcutoff=&tmm_term_cutoff,
16005 +                        doccutoff=&tmm_doccutoff*2,
16006 +                        tmptable=&em_user_out_u);
16007 +       %if &EMEXCEPTIONSTRING ne  %then %goto end_topic_train;
16008 +   /* %end; */
16009 +
16010 +        /*get actual number of topics produced*/
16011 +        proc sql noprint; select count(*) into :tmt_act_multi from mult_topics; quit;
16012 +        %let tmt_act_multi=%ktrim(&tmt_act_multi);
16013 +
16014 +
16015 +       %tmt_doc_score(termtopds=mult_termtop, docds=&curdocDs,
16016 +                      outds=&em_norm_out, topicds=mult_topics, newdocds=multdocs,
16017 +                      termsumds=&em_term_sums, prefix=&tmprefix,
16018 +                      pivot=&tmm_norm_pivot,norm=);
16019 +
16020 +       /*    proc corr data=multdocs; run; */
16021 +
16022 +
16023 +%let endnum=%eval(&startnum + &tmt_act_multi -1);
16024 +%let cnt=%eval(&endnum-&startnum+1);
16025 +
16026 +           /* Set document cutoffs based on average + standard deviation */
16027 +           data _doc_tmp_sums (keep=_doccutoff _mean_ _std_ _ssi_ _ndoc_ _topicid);
16028 +           array vals{&cnt} &tmprefix.raw&startnum -&tmprefix.raw&endnum;
16029 +           array sums{&cnt} _temporary_ (&cnt*0);
16030 +           array ss{&cnt} _temporary_ (&cnt*0);
16031 +           _ndoc_=0;
16032 +           do until(eof);
16033 +              set multdocs end=eof;
16034 +              _ndoc_=_ndoc_+1;
16035 +              do i=1 to &cnt;
16036 +                 sums{i}=sums{i}+abs(vals{i});
16037 +                 ss{i}=ss{i}+abs(vals{i})**2;
16038 +                 end;
16039 +              end;
16040 +           do i=1 to &cnt;
16041 +              _mean_=sums{i}/_ndoc_;
16042 +              _std_=sqrt((ss{i} - _ndoc_*_mean_*_mean_)/(_ndoc_-1));
16043 +              _doccutoff=round(_mean_+_std_,.001);
16044 +              _topicid=i+&startnum-1;
16045 +              _ssi_=ss{i};
16046 +              output;
16047 +              end;
16048 +
16049 +           proc sql noprint;
16050 +               create table mult_topics as
16051 +                  select a._topicid, _name, _cat, /*, _apply */ _numterms, _numdocs,
16052 +                    _termCutoff, b._doccutoff
16053 +                  from mult_topics as a, _doc_tmp_sums as b
16054 +                  where a._topicid=b._topicid;
16055 +           /* proc print data=mult_topics; run; */
16056 +
16057 +       /* Now rescore based on new cutoffs */
16058 +       %tmt_doc_score(termtopds=mult_termtop, docds=&curdocDs,
16059 +                      outds=&em_norm_out, topicds=mult_topics, newdocds=multdocs,
16060 +                      termsumds=&em_term_sums, prefix=&tmprefix,
16061 +                      pivot=&tmm_norm_pivot);
16062 +       %let _ndel=%eval(&tmt_act_multi-&tmt_num_multi);
16063 +
16064 +       %if &_ndel > 0 %then %do;
16065 +          %tmt_remove_dups(in=multdocs,n=%eval(&ntopics+&tmt_act_multi),
16066 +                           m=&user_ntopics, m1=%eval(&ntopics+1),
16067 +                           prefix=&tmprefix.raw,out=&em_doc_ds,
16068 +                           ndel=&_ndel,
16069 +                           topicds=mult_topics, termtopicds=mult_termtop);
16070 +          %let ntopics=%eval(&ntopics+&tmt_act_multi-&_ndel);
16071 +          %end;
16072 +           %else %let ntopics=%eval(&ntopics+&tmt_act_multi);;
16073 +
16074 +      %let curdocDs=&em_doc_ds; /* pass output of remove_dup_tops */
16075 +      data &em_topics; set &em_topics mult_topics; run;
16076 +      data &em_termtopics; set &em_termtopics mult_termtop; run;
16077 +%if &tm_debug =0 %then %do;
16078 +proc sql;
16079 +   drop table out_u;
16080 +   drop table _factors;
16081 +   drop table _factrot;
16082 +   drop table _termmrg;
16083 +   drop table mult_termtop;
16084 +   drop view _tmp_top_weights;
16085 +   drop table _termtmpsums;
16086 +   drop table mult_topics;
16087 +   drop table mult_termtop;
16088 +   drop table multdocs;
16089 +   drop table _doc_tmp_sums;
16090 +   drop view _doc_tmp_sums;
16091 +quit;
16092 +%end;
16093 +      %if %eval(&syscc)>4 %then %do;
16094 +         %let  EMEXCEPTIONSTRING = exception.server.EMTOOL.GENERICRUNTIMEEXCEPTION;
16095 +         %goto end_topic_train;
16096 +         %end;
16097 +   %end;
16098 +proc sort data=&em_topics; by _topicid; run;
16099 +data &em_topics;
16100 +   length _displayCat $16;
16101 +   set &em_topics;
16102 +   label _topicid    = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topicid_vlabel, NOQUOTE))";
16103 +   label _name        = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topic_vlabel, NOQUOTE))";
16104 +/*   label _cat         = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_category_vlabel, NOQUOTE))";*/
16105 +   * label _apply       = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_apply_vlabel, NOQUOTE))";
16106 +   label _doccutoff   = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_docCutoff_vlabel, NOQUOTE))";
16107 +   label _termcutoff  = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_termCutoff_vlabel, NOQUOTE))";
16108 +   label _numterms    = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_numterms_vlabel, NOQUOTE))";
16109 +   label _numdocs     = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_numdocs_vlabel, NOQUOTE))";
16110 +   label _displayCat  = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_category_vlabel, NOQUOTE))";
16111 +
16112 +   select(ksubstr(_cat,1,1));
16113 +      when('S') _displayCat = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topicsingle_value, NOQUOTE))";
16114 +      when('M') _displayCat = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topicmulti_value, NOQUOTE))";
16115 +      when('U') _displayCat = "%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topicuser_value, NOQUOTE))";
16116 +      otherwise;
16117 +      end;
16118 + run;
16119 +   quit;
16120 +
16121 +   * Set some of the data specific issues for TM_CLIENT_SETTINGS;
16122 +   %let docs_interactive = &curDocDs;
16123 +   %let terms_interactive = &em_term_ds;
16124 +
16125 +   %let docs_view_variables = ;
16126 +   * save out the metadata on the docs table ;
16127 +   proc contents data=&docs_interactive out=work._docs_contents noprint;
16128 +   run;
16129 +
16130 +
16131 +   * get a list of the variables ;
16132 +   %let docs_nobs = ;
16133 +   proc sql noprint;
16134 +      select name into :docs_view_variables separated by ' '
16135 +      from work._docs_contents
16136 +      where name not like 'TextTopic%' and klowcase(name) ne "_document_" and
16137 +         kupcase(name) ne "%kupcase(%trim(%left(&parseVar)))";
16138 +
16139 +      * get a count of the variables ;
16140 +      select count(*) into :docs_nobs
16141 +      from &docs_interactive;
16142 +
16143 +      * delete our temp table ;
16144 +      drop table work._docs_contents;
16145 +
16146 +      * get a count of the variables ;
16147 +      select count(*) into :terms_nobs
16148 +      from &em_term_ds;
16149 +   quit;
16150 +
16151 +   * add the parseVar back in as the first field ;
16152 +   %let docs_view_variables = topic_weight %trim(%left(&parseVar)) &docs_view_variables;
16153 +
16154 +   %em_getname(key=tm_client_settings);
16155 +   proc sort data=&em_user_tm_client_settings;
16156 +      by VIEWER KEY;
16157 +   run;
16158 +
16159 +  %let len = %length(&docs_view_variables);
16160 +   /* %put !!!!!!!!!!!! &len  &docs_view_variables; */
16161 +
16162 +   data work.tm_client_settings;
16163 +       length viewer $80 key $80 value $32000;
16164 +       * document table ;
16165 +       viewer = "DOCUMENTS"; key = "nobs";          value = "&docs_nobs";           output;
16166 +       viewer = "DOCUMENTS"; key = "viewvariables"; value = "&docs_view_variables"; output;
16167 +         viewer = "DOCUMENTS"; key = "parseVariable"; value="&parsevar"; output;
16168 +       * terms table ;
16169 +       viewer = "TERMS";     key = "nobs";          value = "&terms_nobs";          output;
16170 +
16171 +       * augTopics table ;
16172 +       viewer = "TOPICS";    key = "nobs";          value = "&ntopics";         output;
16173 +     run;
16174 +    proc sort data=work.tm_client_settings;
16175 +       by VIEWER KEY;
16176 +    run;
16177 +    data &em_user_tm_client_settings;
16178 +       merge &em_user_tm_client_settings work.tm_client_settings;
16179 +       by VIEWER KEY;
16180 +    run;
16181 +    proc datasets nolist nodetails lib=work;
16182 +       delete tm_client_settings;
16183 +    run;
16184 +    quit;
16185 +   * add the info to EMINFO to forward on to other nodes ;
16186 +   data &EM_DATA_EMINFO;
16187 +      length TARGET KEY $32 DATA $43;
16188 +         target = " ";
16189 +      key="LastTMNode";       data="&EM_NODEID";                    output;
16190 +      key="LastTMNodeType";       data="TextTopic";                    output;
16191 +      key="LastTopic";    data="&EM_NODEID";                    output;
16192 +      key="tm_topic_dataset"; data="&EM_PROPERTY_tm_topic_dataset"; output;
16193 +         key="PRESCORECODE"; data="&EM_NODEID"; output;
16194 +    run;
16195 +
16196 +
16197 +   /* At this point, training is complete.  The three tables have been created
16198 +      that are used in the Topic view property: &em_topics for the topic table,
16199 +      a join of &em_term_ds and &em_termtopics for the terms table, and &em_doc_ds
16200 +      for the documents table.  However, the training, etc. table to be exported
16201 +      from the node will be obtained from the scoring code, as documented below.
16202 +   */
16203 +
16204 +
16205 +  %pre_end_topic_train:
16206 +  %if "%ktrim(&systmutil)" ne "" %then %do;
16207 +        %let EMEXCEPTIONSTRING = EMTOOL.TMUTIL, &systmutil;
16208 +        %put emexceptionstring= "&EMEXCEPTIONSTRING";
16209 +        %let syscc=0;
16210 +         %end;
16211 +
16212 +  %end_topic_train:
16213 +  filename temp;
16214 +%if &tm_debug =0 %then %do;
16215 +proc sql;
16216 +   drop table _userdocs;
16217 +quit;
16218 +%end;
16219 +
16220 +
16221 +%mend train;
NOTE: %INCLUDE (level 1) ending.
NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.TM_GET_LAST_FILTER.SOURCE.
16222 +/* ****************************************************************
16223 + * Copyright (C) 2009 by SAS Institute Inc., Cary, NC 27513
16224 + *
16225 + * Name:             tm_get_last_filter.sas
16226 + * Product:          SAS Text Miner
16227 + * Language:         Sas
16228 + * Script:
16229 + *
16230 + * Usage:
16231 + *
16232 + * Purpose:  macro to get the last filter node and the last parse node in the
16233 + *   diagram that corresponds to the current parse variable.  If there is no filter
16234 + *   node, the filter node is set to the last parse node.
16235 + *
16236 + *
16237 + *
16238 + * History:
16239 + * 14Aug09 Initial Coding
16240 + *
16241 + * Notes:
16242 + *    Returns an error in the following cases:
16243 + *      1. There is no preceding parse node.
16244 + *      2. There is no parse node with the current parse variable.
16245 + *
16246 + * Last Modified By:
16247 + * Last Modified On: Wed Sep 23 15:35:04 2009
16248 + *
16249 + * End
16250 + * ************************************************************** */
16251 +%macro tm_get_last_filter(eminfo=,em_lib=, em_variableset=);
16252 +   %let last_parse_node=;
16253 +   %let last_filter_node=;
16254 +   %let last_prescore_node=;
16255 +   %let server_err=;
16256 +   %let EMEXCEPTIONSTRING=;
16257 +   %let syscc=0;
16258 +
16259 +    /* verify that setinit for SAS Text Miner is currently active */
16260 +    %if %sysfunc(sysprod(PRODNUM107)) ne 1 %then %do;
16261 +       %let EMEXCEPTIONSTRING = EMTOOL.NOTMLICENSE;
16262 +        %goto end_macro;
16263 +        %end;
16264 +
16265 +
16266 +    * find last filter or text parse node if no filter node. ;
16267 +   %if %sysfunc(exist(&eminfo)) %then %do;
16268 +      proc sql noprint;
16269 +      select data into :last_parse_node from &eminfo where key="LastTextParsing";
16270 +         select data into :last_filter_node from &eminfo where key="LastTextFilter";
16271 +         select data into :last_prescore_node from &eminfo where kupcase(key)="PRESCORECODE";
16272 +      quit;
16273 +
16274 +   %end;
16275 +
16276 +   %if &last_parse_node= %then %do;
16277 +      %let EMEXCEPTIONSTRING = EMTOOL.NOPARSINGNODE;
16278 +      %goto end_macro;
16279 +      %end;
16280 +
16281 +   %else %if &last_filter_node= %then %let last_filter_node = %ktrim(&last_parse_node);
16282 +   %else %let last_filter_node = %ktrim(&last_filter_node);
16283 +   %let last_parse_node = %ktrim(&last_parse_node);
16284 +
16285 +   * Check to make sure parse variable is present and still exists;
16286 +   %let parsevar = ;
16287 +   proc sql noprint;
16288 +    select parsevar into :parsevar
16289 +    from &em_lib..&last_filter_node._tmconfig;
16290 +    quit;
16291 +
16292 +    *check for dropped parsevar on input dataset;
16293 +       %let parsevarOK= ;
16294 +       %let parsevarN=%kupcase(%ktrim(&parsevar));
16295 +       data _null_;
16296 +         set &em_variableset(where=(kupcase(NAME)="&parsevarN" and USE in('Y' 'D')));
16297 +         if (ROLE='TEXT' or ROLE='TEXTLOC') then call symput('parsevarOK', strip(ROLE));
16298 +         run;
16299 +       %if(&parsevarOK eq ) %then %do;
16300 +          %let EMEXCEPTIONSTRING = EMTOOL.NOPARSINGVAR;
16301 +          %goto end_macro;
16302 +          %end;
16303 +%end_macro:
16304 +
16305 +%mend tm_get_last_filter;
NOTE: %INCLUDE (level 1) ending.
NOTE: PROCEDURE SQL used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      


NOTE: There were 1 observations read from the data set EMWS1.TEXTTOPIC_VARIABLESET.
      WHERE (KUPCASE(NAME)='_0') and USE in ('D', 'Y');
NOTE: DATA statement used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 6 observations read from the data set EMWS1.TEXTFILTER_EMINFO.
NOTE: The data set EMWS1.TEXTTOPIC_LAST_TM_NODES has 6 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.05 seconds
      cpu time            0.01 seconds
      

NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.ROW_PIVOT_NORMALIZE.SOURCE.
16306 +/* ****************************************************************
16307 + * Copyright (C) 1996 by SAS Institute Inc., Cary, NC 27513
16308 + *
16309 + * Name:             row_pivot_normalize_docs.sas
16310 + * Product:          SAS/GRAPH
16311 + * Language:         Sas
16312 + * Script:
16313 + *
16314 + * Usage:
16315 + *
16316 + * Purpose:          To output a new out table that is normalized so that each
16317 + *  row is normalized so "on average" the sums of squares of the _count_ is 1.
16318 + *
16319 + * History:
16320 + * 05May09 Initial Coding
16321 + *
16322 + * Notes:
16323 + *
16324 + * Last Modified By:
16325 + * Last Modified On: Thu Jan 06 17:08:35 2011
16326 + *
16327 + * End
16328 + * ************************************************************** */
16329 +%macro row_pivot_normalize(transds=,outtransds=,row=,col=,entry=,
16330 +                           col_sumds=, pivot=.5, tmt_config= , tmt_train=1, prefix=);
16332 +   /* Calculate sum of the squared entries for each row */
16333 +proc summary nway data=&transds;
16334 +   class &row;
16335 +   var &entry;
16336 +   output out=_sqrowvals uss=;
16337 +   run;
16339 +   /* Put into &meandiv what the average euclidean length is across rows */
16342 +%if &tmt_train = 1  %then %do;
16343 +   proc sql noprint;
16344 +      select mean(sqrt(&entry)) into :meaneuclen
16345 +      from _sqrowvals;
16346 +   quit;
16347 +   %if &tmt_config ne %then %do;
16348 +      *populate the config file with the mean value;
16349 +      data &tmt_config;
16350 +         set &tmt_config;
16351 +         &prefix._meaneuclen= symget('meaneuclen');
16352 +      run;
16353 +   %end;
16354 +    data _sqrowvals;
16355 +      set _sqrowvals;
16356 +      meaneuclen=symget('meaneuclen');
16357 +      divisor = meaneuclen + (sqrt(&entry) - meaneuclen)*&pivot;
16358 +      drop meaneuclen;
16359 +   run;
16362 +%end;
16363 +%else %do;
16364 +      * grab the mean value from the config file  and put into meaneuclien;
16365 +   data _null_;
16366 +      set &tmt_config;
16367 +      call symput('meaneuclen',&prefix._meaneuclen);
16368 +   run;
16369 +    data _sqrowvals;
16370 +      set _sqrowvals;
16371 +      meaneuclen=symget('meaneuclen');
16372 +      divisor = meaneuclen + (sqrt(&entry) - meaneuclen)*&pivot;
16373 +   run;
16375 +%end;
16380 +proc sql noprint;
16381 +   create table &outtransds as
16382 +      select a.&row,a.&col,a.&entry / divisor as &entry
16383 +      from &transds as a,_sqrowvals as b
16384 +      where a.&row=b.&row;
16385 +   drop table _sqrowvals;
16386 +         quit;
16387 +%if &col_sumds ne %then %do;
16388 +   proc summary nway data=&outtransds;
16389 +   class &col;
16390 +   var &entry;
16391 +   output out=&col_sumds mean=;
16392 +   run;
16393 +%end;
16394 +%mend row_pivot_normalize;
NOTE: %INCLUDE (level 1) ending.
NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.TMT_TOPIFY.SOURCE.
16395 +/* ****************************************************************
16396 + * Copyright (C) 2009 by SAS Institute Inc., Cary, NC 27513
16397 + *
16398 + * Name:             tmt_topify.sas
16399 + * Product:          SAS Text Miner
16400 + * Language:         Sas
16401 + * Script:
16402 + *
16403 + * Usage: %tmt_topify(initds=,termds=,topicds=,termtopicds=,<doccutoff=>);
16404 + *
16405 + * Purpose:  To convert a user-created table containing one row for
16406 + *      each term that contains a weight for each topic into a
16407 + *      normalized form with two tables :
16408 + *      a topic table with one row per topic, and a termtopics table
16409 + *      that has one row per term per topic.
16410 + *
16411 + * Parameters:
16412 + *   initds= The name of a table that contains one line per term per
16413 + * topic.  It must include the variables _topic_ (unique name of
16414 + * topic), _term_ (term text string), _role_ (part of speech or entity
16415 + * type).
16416 + *
16417 + *   termds= The name of a table that contains the terms matched up
16418 + * with their term ids, or key.  This table must include the variables
16419 + * key (the unique term id), term (term text string), role (part of
16420 + * speech or entity type), and parent (term id of parent if term
16421 + * represents a synonym of another term).
16422 + *
16423 + *   topicds= a table name that on output will contain one row per
16424 + * topic.  It contains the variables _topicid(unique identifier of
16425 + * topic, numbered sequentially beginning with 1), _name (unique name of
16426 + * topic), _cat (always set to "User" to indicate user topic), _apply
16427 + * (always set to Y so that topic will create a new variable on scored
16428 + * data representing topic), _doccutoff (set to input _docCutoff
16429 + * parameter), _termcutoff (set to zero), _numterms (set to missing to
16430 + * be calculated later), and _numdocs (set to missing to be calculated
16431 + * later)
16432 + *
16433 + *   topictermds= a table name that on output will contain one row for
16434 + * each term with a weight on each topic.  The variables on this table
16435 + * will be _topicid (unique id for each _topic as identified on
16436 + * topicds table), _termid (term ids as identified from the terms
16437 + * table for the term string and role string), and _weight (the weight
16438 + * to be applied to that term from the initds).
16439 + *
16440 + * History:
16441 + * 06May09 Initial Coding
16442 + *
16443 + * Notes:
16444 + *   The way that the term and role text strings are mapped into term
16445 + * ids via the terms data set obeys the following rules:
16446 + *
16447 + * 0. A normalized text string is created that is a downcased version
16448 + * of the term on the init_ds (since all terms are downcased on the
16449 + * terms table).  A normalized role is created in which roles
16450 + * representing parf of speech are set to have first letter
16451 + * uppercased, and the rest lowercased, again to match the term ds casing.
16452 +
16453 + * 1. If a given row on the initds contains both a non-blank term
16454 + * and role then a row is generated on termtopicds for each
16455 + * term on the term ds with that normalized text string and either
16456 + * that normalized role, or a blank role.
16457 + *
16458 + * 2. Any row on initds that has a blank role and a blank term is
16459 + * ignored.
16460 + *
16461 + * 3. Otherwise, any row that has a blank role matches terms in termds
16462 + * with any role.
16463 + *
16464 + * 4. Otherwise, any row with a blank term matches any terms in termds
16465 + * with the given role.
16466 + *
16467 + * Last Modified By:
16468 + * Last Modified On: Tue May 29 14:19:57 2012
16469 + *
16470 + * End
16471 + * ************************************************************** */
16472 +%macro tmt_topify(initds=,termds=,topicds=,termtopicds=,topic_cutoff_ds=,
16473 +                  doccutoff=.001,termcutoff=.001);
16474 +   data _tmptop (keep=_topic_ _term_ _role_ _weight_);
16475 +   set &initds;
16476 +   /* Normalize data (terms all downcased), roles set as appropriate
16477 +    before output */
16478 +   _term_=klowcase(_term_);
16479 +   if propcase(_role_) in
16480 +      ("Adj","Adv","Aux","Conj","Det","Noun","Num","Part",
16481 +       "Prep", "Pron","Prop", "Verb")
16482 +      then _role_=propcase(_role_);
16483 +   if (_term_ ne ' ' or _role_ ne ' ') and _weight_ ne 0 and _weight_ ne . then output _tmpTop;
16484 +   run;
16485 +
16486 +    /* Now summarize all duplicates as mean of all the rows that are duplicated,
16487 +       for topic_cutoffs.
16488 +     */
16489 +   proc summary nway data=&topic_cutoff_ds;
16490 +   class _name;
16491 +   var _docCutoff _termCutoff;
16492 +   output out=&topic_cutoff_ds mean=;
16493 +
16494 +
16495 +   /* Make sure to eliminate duplicates, and to roll children into parents.  Also join
16496 +       with the topic_cutoff_ds to get term and document cutoffs */
16497 +   proc sql noprint;
16498 +      create table _tmptop as
16499 +         select a.*, b._doccutoff, b._termcutoff
16500 +         from _tmptop as a left join &topic_cutoff_ds as b
16501 +         on upcase(a._topic_)=upcase(b._name);
16502 +            quit;
16503 +
16504 +   proc sql noprint;
16505 +      create table _termtop1  as
16506 +         select a._topic_,
16507 +            case
16508 +              when b.parent=. then b.key else b.parent end
16509 +              as _termid, a._weight_ as _weight, a._doccutoff, a._termcutoff
16510 +         from &termds as b,_tmpTop as a
16511 +         where (b.key ne b.parent) and (a._term_= ' ' and a._role_=b.role);
16512 +            quit;
16513 +   proc sql noprint;
16514 +      create table _termtop2  as
16515 +         select a._topic_,
16516 +            case
16517 +              when b.parent=. then b.key else b.parent end
16518 +              as _termid, a._weight_ as _weight, a._doccutoff, a._termcutoff
16519 +         from &termds as b,_tmpTop as a
16520 +         where (b.key ne b.parent) and
16521 +         (a._term_ ne ' ' and a._role_ = ' ' and a._term_=b.term);
16522 +            quit;
16523 +   proc sql noprint;
16524 +      create table _termtop3  as
16525 +         select a._topic_,
16526 +            case
16527 +              when b.parent=. then b.key else b.parent end
16528 +              as _termid, a._weight_ as _weight, a._doccutoff, a._termcutoff
16529 +         from &termds as b,_tmpTop as a
16530 +         where (b.key ne b.parent) and
16531 +               (a._term_ ne ' ' and a._role_ ne ' ' and a._term_=b.term
16532 +                 and (a._role_=b.role or b.role=' '));
16533 +            quit;
16534 +
16535 +
16536 +   data &termtopicds;
16537 +            set _termtop1 _termtop2 _termtop3; run;
16538 +
16539 +   proc sort data=&termtopicds; by _topic_;
16540 +
16541 +   /* Now create the topic data set, which has one row per topic, and
16542 +    the convert the termtopic data set to have one row per actual term
16543 +    per topic */
16544 +   data &topicds (keep=_topicid _name _displayCat _cat _docCutoff _termCutoff
16545 +                  _numterms _numdocs)
16546 +      &termtopicds (keep=_topicid _termid _weight);
16547 +   retain _topicid;
16548 +   format _docCutoff _termCutoff _weight 5.3;
16549 +   set &termtopicds; by _topic_;
16550 +   if _n_=1 then _topicid=1;
16551 +
16552 +   output &termtopicds;
16553 +   if last._topic_ then do;
16554 +      _name=_topic_;
16555 +      _cat="User";
16556 +      _displayCat="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topicuser_value, NOQUOTE))";
16557 +      if _doccutoff=. then _docCutoff=&doccutoff;
16558 +      if _termcutoff=. then  _termcutoff=&termcutoff;
16559 +      _numterms=.;
16560 +      _numdocs=.;
16561 +      output &topicds;
16562 +      _topicid=_topicid+1;
16563 +      end;
16564 +   run;
16565 +
16566 +   /* Replace duplicates with their mean weight */
16567 +   proc summary nway data=&termtopicds;
16568 +   class _topicid _termid;
16569 +   var _weight;
16570 +   output out=&termtopicds mean=;
16571 +   run;
16572 +   data &termtopicds; set &termtopicds(drop=_type_ _freq_); run;
16573 +
16574 +%if &tm_debug =0 %then %do;
16575 +proc sql;
16576 +   drop table _termtop1;
16577 +   drop table _termtop2;
16578 +   drop table _termtop3;
16579 +   quit;
16580 +%end;
16581 +%mend;
NOTE: %INCLUDE (level 1) ending.
NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.TMT_DOC_SCORE.SOURCE.
16582 +/* ****************************************************************
16583 + * Copyright (C) 2010 by SAS Institute Inc., Cary, NC 27513
16584 + *
16585 + * Name:             tmt_doc_score.sas
16586 + * Support:          cox  James A. Cox
16587 + * Product:          SAS Text Miner
16588 + * Language:         Sas
16589 + * Script:
16590 + *
16591 + * Usage:
16592 + *
16593 + * Purpose:  To score documents based on contents of a topic table (&topicds), a term-topic table
16594 + *      (&termtopds), and a weighted "out" table (&outds).  A topic weight is a weighted sum of the
16595 + *      term weights from the term-topic table  (_weight_) where such weight is above a minimum
16596 + *      _termcutoff,  multiplied by the weighted _count_ (_count_) from the weighted "out" table,
16597 + *      where such counts are the tfidf weighted counts.
16598 + *
16599 + *
16600 + * History:
16601 + * 01May09 Initial Coding [cox]
16602 + * 08Nov10 Changed to use hash tables [cox]
16603 + *
16604 + * Notes:
16605 + *   scoring=yes is passed in in topic_score.source for both flow and saved score code.
16606 + *       Otherwise, a blank value is passed in.
16607 + *   docds is blank only when called from the Topic Viewer, since the new document table does
16608 + *       not need to be recalculated until scoring time ( a view is actually displayed that joins
16609 + *        them in the Document table part).  So when scoring is nonblank, docds is
16610 + *       never non-blank.
16611 + *
16612 + *   This routine will score topics inclusive from the minimum topic number (computed internally as
16613 + *        &_mintopic) to the maximum topic number (computed as &_maxtopic) from the input topic data
16614 + *        set.
16615 + *
16616 + *
16617 + *   If &scoring is blank, then topic variables are created for each such topic as <nodename>_#.
16618 + *    For example, if the smallest topic number in topic table is 4 and the largest is 10, and the
16619 + *    nodename is "texttopic", then Texttopic_4-TextTopic10 will be created on the output &newdocds.
16620 + *    In this case, the topic table is updated for the variables _numterms and _numdocs to have the
16621 + *    number of terms and documents that exceed their "minimum" value as indicated on the topic ds.
16622 + *   If &scoring is nonblank, the same variables will contain either 1 (if the weighted sum >=
16623 + *    _docCutoff) or 0 (if it is not).  In this case, variables including a raw suffix will indicate
16624 + *   the raw values as calculated above (e.g. texttopic_raw4-texttopic_raw10).  Also, the topic ds
16625 + *    is NOT updated when scoring.
16626 + *
16627 + *   If docds is passed in, then all variables are added to existing variables on the docds.  In this
16628 + *     case, any documents that have no terms for any of the topics will have 0 for all topic variables.
16629 + *     If docds is not passed in, of course, no concatenation is done, and topics that have no terms
16630 + *     for any of the topics will not appear.
16631 + *
16632 + * Unit Tests:  These unit tests were performed satisfactorily from 11/05-11/23 on this code:
16633 + *   Used existing topic node results to work from... this involves using an existing Text Topic Node and
16634 + *   then rescoring the topics.  Unfortunately, it is not quite this easy since the current tmt_doc_score
16635 + *   also normalizes the topic weights each time it is called for all current topics.  This is incorrect, which
16636 + *   was part of the motivation for this rewrite.  I was able to verify same results using some transformations,
16637 + *   however.
16638 + *
16639 + *   1. Verify that when docds= valid value, that the newdocds contains the new variables, and set to the new
16640 + *       values when they differ from the old ones.  Also that it only has the
16641 + *      new variables when docds is not passed in.
16642 + *   2. Verify that when scoring=yes, the _numdocs and _numterms is not updated, but that the _# variables and
16643 + *      the raw_# variables ARE created, and that the number of 1s in each _# variable is correct based on the
16644 + *      document cutoffs specified.
16645 + *   3. Verify that when scoring=, _numdocs and _numterms IS updated, but that _numterms is the same as was
16646 + *      generated by tmt_doc_score before, and _numdocs is equal to the count of the # of 1s in each topic
16647 + *      variable as generated in the result from 2. above.
16648 + *   4. Verify that the results obtained using tmt_doc_score can be made equivalent to this by performing the
16649 + *      normalization before this code is called.  This was tried for scoring=,docds=, and for scoring=y,
16650 + *      docds=train ds, and scoring=,docds
16651 + *   5. Verify that subsetting topics from 4-10 generate same results for those topics as for topics 1-10.  This
16652 + *      was verified for both scoring=yes and scoring=no.
16653 + *   6. Show that documents that contain no terms for all topics appear and generate 0s for all topic scores when
16654 + *      docds is passed in, but don't appear when docds is not passed in.
16655 + *
16656 + *
16657 + * Last Modified By:
16658 + * Last Modified On: Tue Oct 22 15:19:28 2013
16659 + *
16660 + * End
16661 + * ************************************************************** */
16662 +%macro tmt_doc_score(termtopds=tmp_term_topics,outds=,docds=,newdocds=work.topdocs,
16663 +                     topicds=tmp_topics, termsumds=,scoring=,prefix=_topic,
16664 +                     pivot=.5,norm=,outpos=,topicpos=);
16665 +%let _mintopic=1;
16666 +
16667 +/* Remove any duplicate topic ids before scoring */
16668 +proc sort data=&topicds nodupkey; by _topicid;
16669 +proc sort data=&termtopds nodupkey; by _termid _topicid; run;
16670 +proc sql noprint;
16671 +    select max(_topicid), min(_topicid) into :_maxtopic, :_mintopic from &topicds;
16672 +       quit;
16673 +%if &_mintopic eq . %then %let _mintopic=1;
16674 +/*
16675 +%if &scoring ne %then %do;
16676 +    %let _mintopic=1;
16677 +%end;
16678 +*/
16679 +
16680 +%let _mintopic=%left(&_mintopic);
16681 +%let _maxtopic=%left(&_maxtopic);
16682 +
16683 +/* Do the following if there are any topics to be scored */
16684 +%if &_maxtopic >0 %then %do;
16685 +
16686 +%let _minlab=%ktrim(_tmlab)&_mintopic;
16687 +%let _maxlab=%ktrim(_tmlab)&_maxtopic;
16688 +proc sql noprint;
16689 +    select _name into :&_minlab - :&_maxlab from &topicds;
16690 +       quit;
16691 +
16692 +data &newdocds (drop=_topicid _doccutoff _termCutoff _name _cat _displaycat  _numterms _numdocs
16693 +                _weight _termid rc _termnum_ i _count_)
16694 +   %if &scoring= %then %do;
16695 +      &topicds (keep=_topicid _name _cat _displaycat _numterms _numdocs _docCutoff _termCutoff)
16696 +         %end;
16697 +   %if &outpos ne and &topicpos ne %then %do;
16698 +      &topicpos (keep=_topicid _document_ _offset_ _length_ _termnum_)
16699 +         %end;
16700 +   ;
16701 +   if 0 then set &topicds &termtopds;
16702 +
16703 +   /* Create topic hash table */
16704 +   dcl hash _topic_hash(dataset: "&topicds", ordered: "a");
16705 +   _topic_hash.defineKey("_topicid");
16706 +   _topic_hash.defineData("_topicid","_docCutoff","_termCutoff","_name","_cat","_numterms",
16707 +                     "_numdocs");
16708 +   _topic_hash.defineDone();
16709 +
16710 +   dcl hiter _it_topic("_topic_hash");
16711 +
16712 +   /* Unless we are scoring, zero out _numterms and _numdocs since we will recalculate based on
16713 +    currently specified cutoffs
16714 +    */
16715 +   %if &scoring= %then %do;
16716 +      rc=_it_topic.first();
16717 +      do while(rc=0);
16718 +         _numterms=0; _numdocs=0;
16719 +         _topic_hash.replace();
16720 +         rc=_it_topic.next();
16721 +         end;
16722 +      %end;
16723 +
16724 +   /* Create term-topic hash table */
16725 +   dcl hash _termtopics(multidata: "Y");
16726 +   _termtopics.defineKey("_termid");
16727 +   _termtopics.defineData("_termid","_topicid", "_weight");
16728 +   _termtopics.defineDone();
16729 +
16730 +   /* Now read in observations, and, for every one whose abs(weight) >= _termCutoff, add
16731 +    it to _termtopics hash table and increment the _numdocs count in the topics hash table
16732 +    */
16733 +   do until(eof);
16734 +      set &termtopds end=eof;
16735 +      if _topic_hash.find() ne 0 then do;
16736 +         put "topic " _topicid " not found in topic data set";
16737 +         end;
16738 +      else if abs(_weight)>= _termCutoff then do;
16739 +
16740 +         /* If we are not scoring, adjust the term counts */
16741 +         %if &scoring= %then %do;
16742 +            _numterms+1;
16743 +            _topic_hash.replace();
16744 +            %end;
16745 +
16746 +         /* Add to _termtopics */
16747 +         _termtopics.add();
16748 +         end;
16749 +      end;
16750 +
16751 +   /* Now create document hash table. This will have one row for each document, and contain the
16752 +      weighted topic values for each of the topics on that one row.
16753 +    */
16754 +   array _topic{&_mintopic:&_maxtopic} &prefix.raw&_mintopic-&prefix.raw&_maxtopic;
16755 +   format &prefix.raw&_mintopic-&prefix.raw&_maxtopic 5.3;
16756 +      %if &scoring ne %then %do;
16757 +         array trunc{&_mintopic:&_maxtopic} &prefix.&_mintopic-&prefix.&_maxtopic;
16758 +         array notrunc{&_mintopic:&_maxtopic} &prefix.raw&_mintopic-&prefix.raw&_maxtopic;
16759 +         /* %put "using superq"; */
16760 +         %do i=&_mintopic %to &_maxtopic;
16761 +            /* %put &_tm_tmp; */
16762 +            %let _tm_tmp=_1_0_%bquote(&&_tmlab&i);
16763 +            label &prefix.&i="&_tm_tmp";
16764 +            %let _tm_tmp=%bquote(&&_tmlab&i);
16765 +            label &prefix.raw&i="&_tm_tmp";
16766 +            %end;
16767 +
16768 +         %end;
16769 +
16770 +   dcl hash _doc_hash(hashexp:16,ordered: 'a');
16771 +   _doc_hash.defineKey("_document_");
16772 +   _doc_hash.defineData("_document_"
16773 +                    %do i=&_mintopic %to &_maxtopic; ,"&prefix.raw&i" %end;
16774 +                    );
16775 +   _doc_hash.defineDone();
16776 +
16777 +   /* Now read in out data set */
16778 +   eof=0;
16779 +   do until(eof);
16780 +      set &outds end=eof;
16781 +
16782 +      /* If we haven't seen this document yet, set all topic weights to zero */
16783 +      if _doc_hash.find() ne 0 then do;
16784 +         do i=&_mintopic to &_maxtopic;
16785 +            _topic{i}=0;
16786 +            end;
16787 +         _doc_hash.add();
16788 +         end;
16789 +
16790 +      /* Check to see if this term has significant weights on any topics */
16791 +      _termid=_termnum_;
16792 +      rc=_termtopics.find();
16793 +      if rc = 0 then do;
16794 +         do while(rc=0);
16795 +            _topic{_topicid}= _topic{_topicid}+_weight*_count_;
16796 +            rc=_termtopics.find_next();
16797 +            end;
16798 +         _doc_hash.replace();
16799 +         end;
16800 +      end;
16801 +   _doc_hash.output(dataset: "docds");
16802 +
16803 +   /****************************************************************************
16804 +    * Following is new code for tmt_doc_score_new.  Should be moved into %tmt_doc_score
16805 +    * for 9.4
16806 +    ****************************************************************************/
16807 +
16808 +   %if &outpos ne and &topicpos ne %then %do;
16809 +   /* Now read in outpos data set */
16810 +   eof=0;
16811 +   do until(eof);
16812 +      set &outpos end=eof;
16813 +      if _doc_hash.find() = 0 then do;
16814 +         /* Check to see if this term and document are both in the topic.  If so, output */
16815 +         _termid=_termnum_;
16816 +         rc=_termtopics.find();
16817 +         do while(rc=0);
16818 +            if _topic_hash.find()=0 then
16819 +               if round( _topic{_topicid},.001) >= _doccutoff then output &topicpos;
16820 +            rc=_termtopics.find_next();
16821 +            end;
16822 +         end;
16823 +               else put 'document ' _document_ ' not found.';
16824 +      end;
16825 +
16826 +
16827 +    %end;
16828 +
16829 +   /****************************************************************************
16830 +    * end of new code
16831 +    ****************************************************************************/
16832 +
16833 +   /* Now we have info in the docds hash table for cumulative weights.  Prepare for output and
16834 +      create numdocs for the topics hash table */
16835 +
16836 +   /* Note: If a docds was passed in, we load it here... this accounts for documents that have no
16837 +      positive topic weights.  Otherwise, we process docds hash table iteratively
16838 +    */
16839 +   %if &docds= %then %do;
16840 +      dcl hiter _doc_it("_doc_hash");
16841 +      rc=_doc_itfirst();
16842 +      do while(rc=0);
16843 +         %end;
16844 +      %else %do;
16845 +         eof=0;
16846 +         do until(eof);
16847 +            set &docds end=eof;
16848 +            rc=_doc_hash.find();
16849 +            %end;
16850 +         if rc ne 0 then
16851 +            do i=&_mintopic to &_maxtopic;
16852 +               _topic{i}=0; %if &scoring ne %then trunc{i} = 0;;
16853 +               end;
16854 +         else do _topicid=&_mintopic to &_maxtopic;
16855 +            /* Round value to nearest thousandth */
16856 +            _topic{_topicid}=round( _topic{_topicid},.001);
16857 +            _topic_hash.find();
16858 +            if _topic{_topicid} >= _doccutoff then do;
16859 +               %if &scoring= %then %do;
16860 +                  _numdocs=_numdocs+1;
16861 +                  _topic_hash.replace();
16862 +                  end;
16863 +                  %end;
16864 +               %else %do;
16865 +                  trunc{_topicid} = 1;
16866 +                  end;
16867 +            else trunc{_topicid} = 0;
16868 +            %end;
16869 +         end;
16870 +         output &newdocds;
16871 +       %if &docds= %then rc=_doc_itnext();;
16872 +       end;
16873 +
16874 +   %if &scoring= %then %do;
16875 +      eof=0;
16876 +      do until(eof);
16877 +         set &topicds end=eof;
16878 +         rc=_topic_hash.find();
16879 +         output &topicds;
16880 +         end;
16881 +      %end;
16882 +   * _termtopics.output(dataset: "&termtopds");
16883 +   run;
16884 +
16885 +/* proc sort data=&termtopds; by _topicid _termid; run; */
16886 +%end;
16887 +%else %if &docds ne %then %do;
16888 +    /* If there were no documents,set the new document table to contain the old documents */
16889 +    data &newdocds;
16890 +        set &docds;
16891 +    run;
16892 +
16893 +%end;
16894 +
16895 +%mend;
NOTE: %INCLUDE (level 1) ending.
NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.TMT_REMOVE_DUPS.SOURCE.
16896 +/* ****************************************************************
16897 + * Copyright (C) 2010 by SAS Institute Inc., Cary, NC 27513
16898 + *
16899 + * Name:             tmt_remove_dups.sas
16900 + * Product:          SAS Text Miner
16901 + * Language:         Sas
16902 + * Script:
16903 + *
16904 + * Usage:
16905 + * %tmt_remove_dups(in=tmp , N= , M= , maxc= , t= , prefix=, out=, outN=, outI=);
16906 + *  (see additional parameters in Notes below).
16907 + *
16908 + * Purpose: To remove N-M-maxc topics out of the inputs provided.  The topics that are removed
16909 + *          are the last N-M topics that have the highest correlations with the first M topics .
16910 + *          The first M factors indicate topics that will always persist to output.
16911 +
16912 +*inputs
16913 +    in: input data set with only required variables being &prefix1-&prefixN with rows being
16914 +    the document weight associated with each factor (topic)
16915 +
16916 +    N: total number of factors
16917 +
16918 +    M: number of user factors that will definitely persist to output.  factor1-factorM are
16919 +    taken as user factors unless M=0 (in which case there are no user factors...)
16920 +
16921 +    ndel: number of topics to delete
16922 +
16923 +    prefix: topic variable name prefix, these add a suffix that are 1..N.
16924 +    kpTmp: variable that will cause temporary (work) datasets used internally to be retained
16925 +
16926 + * outputs
16927 +    out: output dataset--will contain factorI variables representing distinct topic;
16928 +    any user topics will persist in factor1-factorM; also, any non-prefix variables will
16929 +    be copied directly to out
16930 +
16931 +    topicds/termtopicds: data sets which will have the _topicid variable updated according to the
16932 +       new index
16933 + *
16934 + * Purpose:
16935 + *
16936 + * History:
16937 + * 18Oct10 Initial Coding
16938 + *
16939 + * Notes:
16940 + *
16941 + * Last Modified By:
16942 + * Last Modified On: Tue Aug 23 15:37:30 2011
16943 + *
16944 + * End
16945 + * ************************************************************** */
16946 +%macro tmt_remove_dups(in=, N=, M=, m1=, ndel=1, prefix=factor,
16947 +                       out=outTops, outN=outN, topicds=,
16948 +                       termtopicds=, kpTmp=);
16949 +  /* %let M1=%eval(&M+1); */
16950 +
16951 +  proc corr noprint outp=tm_tmpcorr data=&in;
16952 +   var &prefix.1-&prefix.&M;
16953 +   with &prefix.&M1-&prefix.&N;
16954 +   run;
16955 +
16956 +  /* proc print data=tm_tmpcorr (where=(_type_="CORR")); run; */
16957 +
16958 +  data _null_;
16959 +   length oldvar_str newvar_str $1000;
16960 +   array corrs{*} &prefix.1-&prefix.&M;
16961 +   dcl hash topcorrs(ordered: "d");
16962 +   topcorrs.defineKey("maxcorr","topicnum");
16963 +   topcorrs.defineData("maxcorr","topicnum");
16964 +   topcorrs.defineDone();
16965 +   topicnum=&M1;
16966 +   do until(eof);
16967 +      set tm_tmpcorr(where=(_type_="CORR")) end=eof;
16968 +      maxcorr=-1;
16969 +      do i=1 to &M;
16970 +         if corrs{i}>maxcorr then maxcorr=corrs{i};
16971 +         end;
16972 +      topcorrs.add();
16973 +      topicnum+1;
16974 +      end;
16975 +   topcorrs.output(dataset: 'corrs');
16976 +   dcl hash remove_vars(ordered: "d");
16977 +   remove_vars.defineKey("topicnum");
16978 +   remove_vars.defineData("maxcorr","topicnum");
16979 +   remove_vars.defineDone();
16980 +
16981 +   dcl hiter corr_it('topcorrs');
16982 +   rc=corr_it.first();
16983 +   do i=1 to &ndel;
16984 +      remove_vars.add();
16985 +      rc=corr_it.next();
16986 +      end;
16987 +   remove_vars.output(dataset: 'rem_corrs');
16988 +
16989 +   oldvar_str="";
16990 +   newvar_str="";
16991 +   dcl hiter var_it('remove_vars');
16992 +   i=&N;
16993 +   rc=var_it.first();
16994 +   do while(rc=0);
16995 +      do while( remove_vars.check(key: i) = 0); i=i-1; /* put i= topicnum=;*/ end;
16996 +      if topicnum<&N-&ndel+1 then do;
16997 +         oldvar_str=ktrim(kleft(put(topicnum,5.))) || " " || oldvar_str;
16998 +         newvar_str=ktrim(kleft(put(i,5.))) || " " || newvar_str;
16999 +         i=i-1;
17000 +         end;
17001 +      else do;
17002 +         oldvar_str=ktrim(kleft(put(topicnum,5.))) || " " || oldvar_str;
17003 +         newvar_str=ktrim(kleft(put(topicnum,5.))) || " " || newvar_str;
17004 +         end;
17005 +
17006 +      rc=var_it.next();
17007 +      end;
17008 +
17009 +   /* oldvar_str contains the topics to be replaced by the topics in the newvar_str */
17010 +   /* put oldvar_str= newvar_str=; */
17011 +
17012 +   call symput('tmt_oldvar_str', oldvar_str);
17013 +   call symput('tmt_newvar_str', newvar_str);
17014 +
17015 +   run;
17016 +
17017 +/* proc print data=corrs; run;  */
17018 +
17019 +
17020 +data &out (drop=&prefix.%eval(&N-&ndel+1)-&prefix.&N);
17021 +   set &in;
17022 +
17023 +   %let index=1;
17024 +   %let source=%scan(&tmt_oldvar_str,&index);
17025 +   %do %while(&source ne);
17026 +      %let dest=%scan(&tmt_newvar_str,&index);
17027 +      &prefix.&source=&prefix.&dest;
17028 +      %let index=%eval(&index+1);
17029 +      %let source=%scan(&tmt_oldvar_str,&index);
17030 +      %end;
17031 +
17032 +data &topicds;
17033 +   set &topicds;
17034 +   %let index=1;
17035 +   %let source=%scan(&tmt_oldvar_str,&index);
17036 +   %if &source ne %then %do;
17037 +      if
17038 +         %do %while(&source ne);
17039 +            %let dest=%scan(&tmt_newvar_str,&index);
17040 +            _topicid=&source then delete;
17041 +            else if _topicid=&dest then _topicid=&source;
17042 +            %let index=%eval(&index+1);
17043 +            %let source=%scan(&tmt_oldvar_str,&index);
17044 +            %if &source ne %then else if;
17045 +               %else %do;
17046 +                  else if _topicid > %eval(&N-&ndel) then delete;
17047 +                  %end;
17048 +            %end;
17049 +      %end;
17050 +   run;
17051 +
17052 +data &termtopicds;
17053 +   set &termtopicds;
17054 +   %let index=1;
17055 +   %let source=%scan(&tmt_oldvar_str,&index);
17056 +   %if &source ne %then %do;
17057 +      if
17058 +         %do %while(&source ne);
17059 +            %let dest=%scan(&tmt_newvar_str,&index);
17060 +            _topicid=&source then delete;
17061 +            else if _topicid=&dest then _topicid=&source;
17062 +            %let index=%eval(&index+1);
17063 +            %let source=%scan(&tmt_oldvar_str,&index);
17064 +            %if &source ne %then else if;
17065 +               %else %do;
17066 +                  else if _topicid > %eval(&N-&ndel) then delete;
17067 +                  %end;
17068 +            %end;
17069 +      %end;
17070 +   run;
17071 +
17072 +%mend;
NOTE: %INCLUDE (level 1) ending.

NOTE: There were 0 observations read from the data set EMWS1.TEXTTOPIC_VARIABLESET.
      WHERE (ROLE='TARGET') and USE in ('D', 'Y') and (LEVEL not = 'INTERVAL');
NOTE: DATA statement used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 1 observations read from the data set EMWS1.TEXTFILTER_TMCONFIG.
NOTE: DATA statement used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 42119 observations read from the data set EMWS1.TEXTFILTER_TMOUT.
NOTE: There were 3619 observations read from the data set EMWS1.TEXTFILTER_TERMS_DATA.
      WHERE KEEP='Y';
NOTE: There were 20589 observations read from the data set EMWS1.TEXTFILTER_TERM_STRINGS.
NOTE: PROCEDURE TMUTIL used (Total process time):
      real time           0.08 seconds
      cpu time            0.04 seconds
      


NOTE: There were 22457 observations read from the data set EMWS1.TEXTFILTER_TERMS_DATA.
NOTE: The data set EMWS1.TEXTTOPIC_WEIGHTEDTMOUT has 41987 observations and 3 variables.
NOTE: PROCEDURE TMUTIL used (Total process time):
      real time           0.11 seconds
      cpu time            0.01 seconds
      

WARNING: File EMWS1.TEXTTOPIC_WEIGHTEDTERMS.VIEW does not exist.
WARNING: View EMWS1.TEXTTOPIC_WEIGHTEDTERMS has not been dropped.
NOTE: Table EMWS1.TEXTTOPIC_WEIGHTEDTERMS created, with 1575 rows and 13 columns.

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.06 seconds
      cpu time            0.04 seconds
      


NOTE: There were 41987 observations read from the data set EMWS1.TEXTTOPIC_WEIGHTEDTMOUT.
NOTE: The data set WORK._SQROWVALS has 5987 observations and 4 variables.
NOTE: PROCEDURE SUMMARY used (Total process time):
      real time           0.04 seconds
      cpu time            0.03 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      


NOTE: There were 1 observations read from the data set EMWS1.TEXTFILTER_TMCONFIG.
NOTE: The data set EMWS1.TEXTFILTER_TMCONFIG has 1 observations and 30 variables.
NOTE: DATA statement used (Total process time):
      real time           0.03 seconds
      cpu time            0.00 seconds
      


NOTE: Character values have been converted to numeric values at the places given by: (Line):(Column).
      53:109   53:138   
NOTE: There were 5987 observations read from the data set WORK._SQROWVALS.
NOTE: The data set WORK._SQROWVALS has 5987 observations and 5 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      

NOTE: Table EMWS1.TEXTTOPIC_TMOUT_NORMALIZED created, with 41987 rows and 3 columns.

NOTE: Table WORK._SQROWVALS has been dropped.
NOTE: PROCEDURE SQL used (Total process time):
      real time           0.09 seconds
      cpu time            0.04 seconds
      


NOTE: There were 41987 observations read from the data set EMWS1.TEXTTOPIC_TMOUT_NORMALIZED.
NOTE: The data set EMWS1.TEXTTOPIC_TERM_SUMS has 1575 observations and 4 variables.
NOTE: PROCEDURE SUMMARY used (Total process time):
      real time           0.08 seconds
      cpu time            0.04 seconds
      


NOTE: There were 0 observations read from the data set EMWS1.TEXTTOPIC_INITTOPICS.
NOTE: The data set WORK._TMPTOP has 0 observations and 4 variables.
NOTE: DATA statement used (Total process time):
      real time           0.21 seconds
      cpu time            0.01 seconds
      


NOTE: No observations in data set EMWS1.TEXTTOPIC_TOPIC_CUTOFFS.
NOTE: The data set EMWS1.TEXTTOPIC_TOPIC_CUTOFFS has 0 observations and 5 variables.
NOTE: PROCEDURE SUMMARY used (Total process time):
      real time           0.07 seconds
      cpu time            0.03 seconds
      

WARNING: This CREATE TABLE statement recursively references the target table. A consequence of this is a possible data integrity problem.
NOTE: Table WORK._TMPTOP created, with 0 rows and 6 columns.

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.04 seconds
      cpu time            0.03 seconds
      

NOTE: Table WORK._TERMTOP1 created, with 0 rows and 5 columns.

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.04 seconds
      cpu time            0.00 seconds
      

NOTE: Table WORK._TERMTOP2 created, with 0 rows and 5 columns.

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.03 seconds
      cpu time            0.00 seconds
      

NOTE: Table WORK._TERMTOP3 created, with 0 rows and 5 columns.

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      


NOTE: There were 0 observations read from the data set WORK._TERMTOP1.
NOTE: There were 0 observations read from the data set WORK._TERMTOP2.
NOTE: There were 0 observations read from the data set WORK._TERMTOP3.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 0 observations and 5 variables.
NOTE: DATA statement used (Total process time):
      real time           0.04 seconds
      cpu time            0.00 seconds
      


NOTE: Input data set is empty.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 0 observations and 5 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      


NOTE: There were 0 observations read from the data set EMWS1.TEXTTOPIC_TERMTOPICS.
NOTE: The data set EMWS1.TEXTTOPIC_TOPICS has 0 observations and 8 variables.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 0 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.06 seconds
      cpu time            0.00 seconds
      


NOTE: No observations in data set EMWS1.TEXTTOPIC_TERMTOPICS.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 0 observations and 5 variables.
NOTE: PROCEDURE SUMMARY used (Total process time):
      real time           0.02 seconds
      cpu time            0.01 seconds
      


NOTE: There were 0 observations read from the data set EMWS1.TEXTTOPIC_TERMTOPICS.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 0 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: Input data set is empty.
NOTE: 0 observations with duplicate key values were deleted.
NOTE: The data set EMWS1.TEXTTOPIC_TOPICS has 0 observations and 8 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      


NOTE: Input data set is empty.
NOTE: 0 observations with duplicate key values were deleted.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 0 observations and 3 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 6048 observations read from the data set EMWS1.TEXTPARSING_TRAIN.
NOTE: There were 6048 observations read from the data set EMWS1.TEXTFILTER_DOC_IDS.
NOTE: There were 6048 observations read from the data set EMWS1.TEXTFILTER_TRAIN.
NOTE: The data set WORK._USERDOCS has 6048 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.04 seconds
      cpu time            0.03 seconds
      


NOTE: There were 6048 observations read from the data set WORK._USERDOCS.
NOTE: The data set EMWS1.TEXTTOPIC_DOCDS has 6048 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.07 seconds
      cpu time            0.01 seconds
      

NOTE: %INCLUDE (level 1) file TEMP is file SASHELP.EMTXTEXT.TMT_MULTI_TERMS.SOURCE.
17073 +/* ****************************************************************
17074 + * Copyright (C) 2009 by SAS Institute Inc., Cary, NC 27513
17075 + *
17076 + * Name:             tmt_multi_terms.sas
17077 + * Support:          cox  James A. Cox
17078 + * Product:          SAS Text Miner
17079 + * Language:         Sas
17080 + * Script:
17081 + *
17082 + * Usage:
17083 + *
17084 + * Purpose:          Computes an svd of a term by document matrix and
17085 + *                   then rotates the U matrix corresponding to term wgts.
17086 +
17087 + *
17088 + * History:
17089 + * 30Apr09 Initial Coding [cox]
17090 + *
17091 + * Notes:
17092 + *
17093 + * Last Modified By:
17094 + * Last Modified On: Thu Jun 05 16:00:11 2014
17095 + *
17096 + * End
17097 + * ************************************************************** */
17098 +
17099 +%macro tmt_multi_terms(outds=, termds=, num_terms=, num_topics=20,
17100 +                       rotation=varimax,scaleword=,normword=,termtopicds=,
17101 +                       startnum=1,termcutoff=,topicds=multtopics,
17102 +                       prefix=_topic, tmptable=out_u, doccutoff=.1,
17103 +                       termcutoff_multiple=1,rotate_matrix=_termmrg,
17104 +                       svdu=,svd_index=index);
17105 +%if &svdu eq %then %do;
17106 +/*make sure requested topics do not exceed matrix dimensions or spsvd will return an error*/
17107 +%let k_margin=15;
17108 +%let minpertopic=5;
17109 +
17110 +proc sql noprint;
17111 +select count(distinct _termnum_), count(distinct _document_)
17112 +        into :n_termnum_, :n_document_ from &outds;
17113 +quit;
17114 +%if &n_document_ <= &n_termnum_ %then %let k_cutoff=%ktrim(&n_document_);
17115 +%else %let k_cutoff=%ktrim(&n_termnum_);
17116 +
17117 +/* Check for too few documents and two few terms for topic discovery */
17118 +
17119 +%if %eval(&n_termnum_) < &k_margin %then %do;
17120 +   %let EMEXCEPTIONSTRING = EMTOOL.TOPIC_TERMS_SMALL,&n_termnum_;
17121 +   %goto end_multi_terms;
17122 +%end;
17123 +
17124 +%if %eval(&n_document_) < &k_margin %then %do;
17125 +   %let EMEXCEPTIONSTRING = EMTOOL.TOPIC_DATA_SMALL,&n_document_;
17126 +   %goto end_multi_terms;
17127 +%end;
17128 +
17129 +/* Now check to see if data requires fewer topics to be specified than requested.
17130 +     Must be 5 documents and terms per topic */
17131 +%let max_topics= %eval(&k_cutoff/&minpertopic);
17132 +
17133 +
17134 +%if &num_topics>&max_topics %then %do;
17135 +   %put %sysfunc(SASMSG(sashelp.tmine,EMTOOL.TOPIC_DATA_SMALL_WARN,NOQUOTE,&n_document_,&n_termnum_,&max_topics));
17136 +   %let num_topics=&max_topics;
17137 +   %end;
17138 +
17139 +
17140 +proc sort data=&outds; by _termnum_ _document_;
17141 +proc spsvd data=&outds k=&num_topics;
17142 +   row _termnum_;
17143 +   col _document_;
17144 +   entry _count_;
17145 +   output u=&tmptable
17146 +   %if &scaleword ne %then scaleword;
17147 +   %if &normword ne %then normword;
17148 +      ;
17149 +   run;
17150 +
17151 +/*try sampling if out of memory occurred*/
17152 +%if(&syscc eq 1111) %then %do;
17153 +    %let syscc=0; /*reset syscc*/
17154 +    proc spsvd data=&outds k=&num_topics;
17155 +        row _termnum_;
17156 +        col _document_;
17157 +        entry _count_;
17158 +        output v = _sampV u=&tmptable;
17159 +        sample allow;
17160 +    run;
17161 +%end;
17162 +
17163 +%if &syscc > 4 %then %do;
17164 +%let EMEXCEPTIONSTRING = EMTOOL.SPSVDERROR;
17165 +%goto end_multi_terms;
17166 +%end;
17167 +
17168 +%end;
17169 + %else %do;
17170 +   %let tmptable=&svdu;
17171 +    %put tmptable= &tmptable;
17172 +    %end;
17173 +
17174 +proc transpose data=&tmptable (drop=&svd_index) out=_factors(drop=_NAME_);
17175 +   run;
17176 +
17177 +/*get actual number of topics produced*/
17178 +proc sql noprint; select count(*) into :num_topics from _factors; quit;
17179 +%let num_topics=%ktrim(&num_topics);
17180 +
17181 +data _factors(type=factor);
17182 +   set _factors;
17183 +   _TYPE_='PATTERN';
17184 +   _NAME_='factor'|| kleft(put(_N_,4.));
17185 +   run;
17186 +
17187 +proc factor noprint data=_factors method=pattern n=&num_topics
17188 +      rotate=&rotation
17189 +      nocorr outstat=_factrot;
17190 +   run;
17191 +
17192 +/*
17193 +data _factrot (drop=num);
17194 +   length _name_ $15;
17195 +   set _factrot;
17196 +   if _type_='PATTERN' then do;
17197 +      _name_=ktrim(_name_)|| "    ";
17198 +      num=input(substr(_name_,7),4.);
17199 +      _name_="&prefix"|| ktrim(kleft(put(num+&startnum-1,4.)));
17200 +      output;
17201 +      end;
17202 +   run;
17203 + */
17204 +proc transpose data=_factrot(where=(_type_='PATTERN')) out=&rotate_matrix; run;
17205 +      /* proc corr data=&rotate_matrix; run; */
17206 +/*
17207 +proc summary data=&rotate_matrix;
17208 +    var factor1-factor&num_topics;
17209 +   output out=_tmpsums mean=;
17210 +proc print data=_tmpsums; run;
17211 +*/
17212 +proc sort data=&termds(where=(_ispar ne '.')) out=_sortterm; by key;
17213 +data &rotate_matrix;
17214 +   merge _sortterm &rotate_matrix;
17215 +   run;
17216 +/* proc print data=&rotate_matrix(obs=50); id key; var factor1-factor10; run; */
17217 +
17218 +data &termtopicds (keep=_topicid _termid _weight term);
17219 +   array topics{*} factor1-factor&num_topics;
17220 +   set &rotate_matrix;
17221 +   _termid=key;
17222 +   if _ispar='+' then term='+'||term;
17223 +   do i=1 to &num_topics;
17224 +      _topicid=i+&startnum-1;
17225 +      /* Round off weight to be exact in third decimal place */
17226 +      _weight=round(topics{i},0.001);
17227 +      output;
17228 +      end;
17229 +   run;
17230 +
17231 +/* Create temporary view that includes abs_weight */
17232 +proc sql noprint;
17233 +   create view _tmp_top_weights as select *, abs(_weight) as abs_weight
17234 +      from &termtopicds;
17235 +      quit;
17236 +
17237 +proc summary nway data=_tmp_top_weights;
17238 +   class _topicid;
17239 +   var _weight abs_weight;
17240 +   output out=_termtmpsums
17241 +      mean(abs_weight)=abs_weight_mean
17242 +      std(abs_weight)=abs_weight_std
17243 +      idgroup( max(_weight) out[5] (term)=)
17244 +      /autolabel autoname;
17245 +   run;
17246 +data &topicds(keep=_topicid _name _cat _displayCat /* _apply */ _numterms _numdocs
17247 +               _docCutoff _termCutoff);
17248 +   set _termtmpsums;
17249 +   length _name $100;
17250 +   _name=ktrim(term_1)||','||ktrim(term_2)||','||ktrim(term_3)||','||
17251 +      ktrim(term_4)||','||ktrim(term_5);
17252 +   _cat="Mult";
17253 +   _displayCat="%sysfunc(sasmsg(sashelp.tmine,  rpt_text_topicmult_value, NOQUOTE))";
17254 +    /*  _apply="Y"; */
17255 +   /* Change to use mean plus one standard deviation */
17256 +   /* _termCutoff=max(0.001, min(_weight_p99,max(_weight_Max*&termcutoff,_weight_P95))); */
17257 +   _termcutoff= %if &termCutoff ne %then &termcutoff;
17258 +             %else round(abs_weight_mean+abs_weight_std*&termcutoff_multiple,0.001);
17259 +   ;
17260 +   _docCutoff=.;
17261 +   _numterms=.;
17262 +   _numdocs=.;
17263 +
17264 +   run;
17265 +data &termtopicds;
17266 +   set &termtopicds(drop=term);
17267 +   run;
17268 +
17269 +/*post processing: eliminate topics with no terms above the cutoff*/
17270 +proc sql;
17271 +create table kpTops as
17272 +    select distinct a._topicid as _topicid0 from &topicds a, &termtopicds b
17273 +    where a._topicid=b._topicid and abs(b._weight) >= a._termcutoff and b._termid ne .;
17274 +
17275 +alter table kpTops add _topicid num;
17276 +update kpTops set _topicid=monotonic()+&startnum-1;
17277 +
17278 +create table &topicds(drop=_topicid0) as
17279 +    select b._topicid, a.* from &topicds(rename=(_topicid=_topicid0)) a, kpTops b where a._topicid0=b._topicid0;
17280 +
17281 +create table &termtopicds(drop=_topicid0) as
17282 +    select a._termid, b._topicid, a._weight from &termtopicds(rename=(_topicid=_topicid0)) a, kpTops b where a._topicid0=b._topicid0;
17283 +
17284 +drop table kpTops;
17285 +quit;
17286 +
17287 +
17288 + /*    filename temp catalog 'sashelp.emtxtext.svd_rotate.source';
17289 +    %include temp;
17290 +
17291 +    %svd_rotate(termds=&termds,
17292 +                outds=&outds, weight=,
17293 +                out_u=work.out_u, out_term=work.rotsvdmrg,
17294 +                nfactors=&num_terms, rotation=&topic_method,
17295 +                scaleword=,normword=);
17296 +
17297 +*/
17298 +
17299 +%end_multi_terms:
17300 +
17301 +%mend;
NOTE: %INCLUDE (level 1) ending.
NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.02 seconds
      cpu time            0.03 seconds
      


NOTE: There were 41987 observations read from the data set EMWS1.TEXTTOPIC_TMOUT_NORMALIZED.
NOTE: The data set EMWS1.TEXTTOPIC_TMOUT_NORMALIZED has 41987 observations and 3 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.05 seconds
      cpu time            0.01 seconds
      


NOTE: P has been set to 75.
NOTE: Singular values have converged.  Creating data sets.
NOTE: Restarted 0 times.
NOTE: There were 41987 observations read from the data set EMWS1.TEXTTOPIC_TMOUT_NORMALIZED.
NOTE: The data set EMWS1.TEXTTOPIC_OUT_U has 1575 observations and 6 variables.
NOTE: PROCEDURE SPSVD used (Total process time):
      real time           0.08 seconds
      cpu time            0.06 seconds
      


NOTE: There were 1575 observations read from the data set EMWS1.TEXTTOPIC_OUT_U.
NOTE: The data set WORK._FACTORS has 5 observations and 1575 variables.
NOTE: PROCEDURE TRANSPOSE used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 5 observations read from the data set WORK._FACTORS.
NOTE: The data set WORK._FACTORS has 5 observations and 1577 variables.
NOTE: DATA statement used (Total process time):
      real time           0.03 seconds
      cpu time            0.01 seconds
      


WARNING: The data set WORK._FACTORS does not indicate how many observations were used to compute the  matrix. The number of observations has been set to 10000. Statistics that depend on the number of observations (such as p-values) are not interpretable.
NOTE: Rotation converged.  Criterion changed from 387454.382 to 867388.543 in 9 cycles.
NOTE: The data set WORK._FACTROT has 14 observations and 1577 variables.
NOTE: At least one W.D format was too small for the number to be printed. The decimal may be shifted by the "BEST" format.
NOTE: PROCEDURE FACTOR used (Total process time):
      real time           0.28 seconds
      cpu time            0.03 seconds
      


NOTE: There were 5 observations read from the data set WORK._FACTROT.
      WHERE _type_='PATTERN';
NOTE: The data set WORK._TERMMRG has 1575 observations and 6 variables.
NOTE: PROCEDURE TRANSPOSE used (Total process time):
      real time           0.02 seconds
      cpu time            0.01 seconds
      

NOTE: Input data set is already sorted; it has been copied to the output data set.
NOTE: There were 1575 observations read from the data set EMWS1.TEXTTOPIC_WEIGHTEDTERMS.
      WHERE _ispar not = '.';
NOTE: The data set WORK._SORTTERM has 1575 observations and 13 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 1575 observations read from the data set WORK._SORTTERM.
NOTE: There were 1575 observations read from the data set WORK._TERMMRG.
NOTE: The data set WORK._TERMMRG has 1575 observations and 19 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: There were 1575 observations read from the data set WORK._TERMMRG.
NOTE: The data set WORK.MULT_TERMTOP has 7875 observations and 4 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

NOTE: SQL view WORK._TMP_TOP_WEIGHTS has been defined.
NOTE: PROCEDURE SQL used (Total process time):
      real time           0.02 seconds
      cpu time            0.00 seconds
      


NOTE: There were 7875 observations read from the data set WORK.MULT_TERMTOP.
NOTE: There were 7875 observations read from the data set WORK._TMP_TOP_WEIGHTS.
NOTE: The data set WORK._TERMTMPSUMS has 5 observations and 10 variables.
NOTE: PROCEDURE SUMMARY used (Total process time):
      real time           0.03 seconds
      cpu time            0.01 seconds
      


NOTE: There were 5 observations read from the data set WORK._TERMTMPSUMS.
NOTE: The data set WORK.MULT_TOPICS has 5 observations and 8 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: There were 7875 observations read from the data set WORK.MULT_TERMTOP.
NOTE: The data set WORK.MULT_TERMTOP has 7875 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

NOTE: Table WORK.KPTOPS created, with 5 rows and 1 columns.

NOTE: Table WORK.KPTOPS has been modified, with 2 columns.
NOTE: 5 rows were updated in WORK.KPTOPS.

WARNING: This CREATE TABLE statement recursively references the target table. A consequence of this is a possible data integrity problem.
NOTE: Table WORK.MULT_TOPICS created, with 5 rows and 8 columns.

WARNING: This CREATE TABLE statement recursively references the target table. A consequence of this is a possible data integrity problem.
WARNING: The variable _topicid0 in the DROP, KEEP, or RENAME list has never been referenced.
NOTE: Table WORK.MULT_TERMTOP created, with 7875 rows and 3 columns.

NOTE: Table WORK.KPTOPS has been dropped.
NOTE: PROCEDURE SQL used (Total process time):
      real time           0.17 seconds
      cpu time            0.06 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: 0 observations with duplicate key values were deleted.
NOTE: The data set WORK.MULT_TOPICS has 5 observations and 8 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: There were 7875 observations read from the data set WORK.MULT_TERMTOP.
NOTE: 0 observations with duplicate key values were deleted.
NOTE: The data set WORK.MULT_TERMTOP has 7875 observations and 3 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      


NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: The data set WORK.DOCDS has 5987 observations and 6 variables.
NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: There were 7875 observations read from the data set WORK.MULT_TERMTOP.
NOTE: There were 41987 observations read from the data set EMWS1.TEXTTOPIC_TMOUT_NORMALIZED.
NOTE: There were 6048 observations read from the data set WORK._USERDOCS.
NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: The data set WORK.MULTDOCS has 6048 observations and 8 variables.
NOTE: The data set WORK.MULT_TOPICS has 5 observations and 8 variables.
NOTE: DATA statement used (Total process time):
      real time           0.24 seconds
      cpu time            0.07 seconds
      


NOTE: There were 6048 observations read from the data set WORK.MULTDOCS.
NOTE: The data set WORK._DOC_TMP_SUMS has 5 observations and 6 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

WARNING: This CREATE TABLE statement recursively references the target table. A consequence of this is a possible data integrity problem.
NOTE: Table WORK.MULT_TOPICS created, with 5 rows and 7 columns.

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: 0 observations with duplicate key values were deleted.
NOTE: The data set WORK.MULT_TOPICS has 5 observations and 7 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


NOTE: Input data set is already sorted, no sorting done.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      

NOTE: PROCEDURE SQL used (Total process time):
      real time           0.00 seconds
      cpu time            0.00 seconds
      


WARNING: The variable _displaycat in the DROP, KEEP, or RENAME list has never been referenced.
WARNING: The variable _displaycat in the DROP, KEEP, or RENAME list has never been referenced.
NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: The data set WORK.DOCDS has 5987 observations and 6 variables.
NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: There were 7875 observations read from the data set WORK.MULT_TERMTOP.
NOTE: There were 41987 observations read from the data set EMWS1.TEXTTOPIC_TMOUT_NORMALIZED.
NOTE: There were 6048 observations read from the data set WORK._USERDOCS.
NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: The data set WORK.MULTDOCS has 6048 observations and 8 variables.
NOTE: The data set WORK.MULT_TOPICS has 5 observations and 7 variables.
NOTE: DATA statement used (Total process time):
      real time           0.07 seconds
      cpu time            0.03 seconds
      


NOTE: There were 0 observations read from the data set EMWS1.TEXTTOPIC_TOPICS.
NOTE: There were 5 observations read from the data set WORK.MULT_TOPICS.
NOTE: The data set EMWS1.TEXTTOPIC_TOPICS has 5 observations and 8 variables.
NOTE: DATA statement used (Total process time):
      real time           0.05 seconds
      cpu time            0.00 seconds
      


NOTE: There were 0 observations read from the data set EMWS1.TEXTTOPIC_TERMTOPICS.
NOTE: There were 7875 observations read from the data set WORK.MULT_TERMTOP.
NOTE: The data set EMWS1.TEXTTOPIC_TERMTOPICS has 7875 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.04 seconds
      cpu time            0.00 seconds
      


NOTE: There were 5 observations read from the data set EMWS1.TEXTTOPIC_TOPICS.
NOTE: The data set EMWS1.TEXTTOPIC_TOPICS has 5 observations and 8 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: There were 5 observations read from the data set EMWS1.TEXTTOPIC_TOPICS.
NOTE: The data set EMWS1.TEXTTOPIC_TOPICS has 5 observations and 8 variables.
NOTE: DATA statement used (Total process time):
      real time           0.04 seconds
      cpu time            0.03 seconds
      


NOTE: The data set WORK._DOCS_CONTENTS has 3 observations and 41 variables.
NOTE: PROCEDURE CONTENTS used (Total process time):
      real time           0.01 seconds
      cpu time            0.01 seconds
      

NOTE: Table WORK._DOCS_CONTENTS has been dropped.
NOTE: PROCEDURE SQL used (Total process time):
      real time           0.18 seconds
      cpu time            0.01 seconds
      


NOTE: There were 13 observations read from the data set EMWS1.TEXTTOPIC_TM_CLIENT_SETTINGS.
NOTE: The data set EMWS1.TEXTTOPIC_TM_CLIENT_SETTINGS has 13 observations and 3 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.12 seconds
      cpu time            0.00 seconds
      


NOTE: The data set WORK.TM_CLIENT_SETTINGS has 5 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.02 seconds
      cpu time            0.00 seconds
      


NOTE: There were 5 observations read from the data set WORK.TM_CLIENT_SETTINGS.
NOTE: The data set WORK.TM_CLIENT_SETTINGS has 5 observations and 3 variables.
NOTE: PROCEDURE SORT used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: There were 13 observations read from the data set EMWS1.TEXTTOPIC_TM_CLIENT_SETTINGS.
NOTE: There were 5 observations read from the data set WORK.TM_CLIENT_SETTINGS.
NOTE: The data set EMWS1.TEXTTOPIC_TM_CLIENT_SETTINGS has 13 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.01 seconds
      cpu time            0.00 seconds
      


NOTE: Deleting WORK.TM_CLIENT_SETTINGS (memtype=DATA).

NOTE: PROCEDURE DATASETS used (Total process time):
      real time           0.00 seconds
      cpu time            0.01 seconds
      


NOTE: The data set EMWS1.TEXTTOPIC_EMINFO has 5 observations and 3 variables.
NOTE: DATA statement used (Total process time):
      real time           0.19 seconds
      cpu time            0.00 seconds
      

NOTE: Fileref TEMP has been deassigned.
17302  *------------------------------------------------------------*;
17303  * End TRAIN: TextTopic;
17304  *------------------------------------------------------------*;
17305  

17306  *------------------------------------------------------------*;
17307  * Close any missing semi colons;
17308  *------------------------------------------------------------*;
17309  ;
17310  ;
17311  ;
17312  ;
17313  quit;
17314  *------------------------------------------------------------*;
17315  * Close any unbalanced quotes;
17316  *------------------------------------------------------------*;
17317  /*; *"; *'; */
17318  ;
17319  run;
17320  quit;
17321  /* Reset EM Options */
17322  options formchar="|----|+|---+=|-/\<>*";
17323  options nocenter ls=256 ps=10000;
17324  goptions reset=all device=GIF NODISPLAY;

